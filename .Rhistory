PRUEBA -> En este tutorial haremos clustering jerárquico, usando como base el mismo data set de Ford Ka, Antes, carguemos los paquetes que necesitamos.
Un reconocimiento a UC Business Analytics R Programming Guide de quien tomé ejemplos del código. Pueden [ver el código acá](https://uc-r.github.io/hc_clustering)
---
title: "Cluster Jerárquico"
author: "Ramiro Casó"
date: "8/26/2020"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Intro
PRUEBA -> En este tutorial haremos clustering jerárquico, usando como base el mismo data set de Ford Ka, Antes, carguemos los paquetes que necesitamos.
Un reconocimiento a UC Business Analytics R Programming Guide de quien tomé ejemplos del código. Pueden [ver el código acá](https://uc-r.github.io/hc_clustering)
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(readxl)     # Lectura o carga de datos
library(tidyr)      # Pipe y manipulación de datos.
library(tidyverse)  # Manipulación de datos.
library(cluster)    # Clusters
library(factoextra) # Visualización
```
Seguidamente cargamos el set de datos. Lo haremos utilizando el data set de Ford Ka. Noten que cargué la hoja que ya tenía en mi working directory. En el comando de read_excel, específiqué la hoja que quería y, además, le quité las primeras 5 líneas, que no contienen información.
```{r message=FALSE, warning=FALSE}
psicograficos <- read_excel("DataSets/Ford_Ka_Students.xls",
sheet = "Psychographic Data", skip = 5)
head(psicograficos)
```
### Normalización
Lo que sigue es normalizar los datos. Hay que dejar en la matriz de datos solo las columnas que usaremos para agrupar, de modo que hay que sacar la primera columna.
```{r}
norm_psico <- scale(psicograficos[,-1])
```
### Clustering
Como vamos a hacer clustering jerárquico usaremos función *agnes* (su nombre viene de "agglomerative nesting").
Para poder hacerlo, tenemos que calcular la disimilaridades en la data, usando la función dist.
```{r}
# Matriz de disimilaridad
d <- dist(norm_psico, method = "euclidean")
# Clustering jerárquico usando el método "complete" de distancia.
hc1 <- hclust(d, method = "complete" )
# construcción del dendograma
plot(hc1, cex = 0.6, hang = -1)
```
Veamos que pasa si usamos otros métodos de cálculo de distancia entre clusters. En este caso, single.
```{r}
# Matriz de disimilaridad es la misma que el caso anterior y está guardada en el objeto d
# Clustering jerárquico usando el método "single" de distancia.
hc2 <- hclust(d, method = "single" )
# construcción del dendograma
plot(hc2, cex = 0.6, hang = -1)
```
Finalmente, probemos el método average.
```{r}
# Matriz de disimilaridad es la misma que el caso anterior y está guardada en el objeto d
# Clustering jerárquico usando el método "single" de distancia.
hc3 <- hclust(d, method = "average")
# construcción del dendograma
plot(hc3, cex = 0.6, hang = -1)
```
La altura de las fusiones en el dendograma, que se pueden apreciar en el eje verticual, indica la disimilaridad entre dos observaciones. Mientras más alta sea la fusión o unión, más diferentes son los observaciones. Nótese que la proximidad de las observaciones NO es un indicador similaridad. Solo la altura arroja esa información.
En razón de lo anterior, la altura a la que se corta un dendograma nos el número de cluster que queremos, similar a la selección de K en k-means. Para poder identificar subgrupos, podemos cortar el dendograma con la función *cutree*
```{r}
# Usaremos el método "complete" que fue el que arrojó el dendograma más claro.
hc5 <- hclust(d, method = "complete" )
# Cortaremos el dendograma en 4 clusters.
sub_grp <- cutree(hc5, k = 4)
# Acá podemos ver los subgrupos creados.
table(sub_grp)
```
Y si queremos agregar las columnas de membresías al data set original, podemos usar la función *mutate* de la siguiente forma.
```{r}
psicograficos %>%
mutate(cluster = sub_grp) %>%
head
```
Se puede inclusive hacer un dendograma resaltando los 4 clusters, de la siguiente forma:
```{r}
plot(hc5, cex = 0.6)
rect.hclust(hc5, k = 4, border = 2:5)
```
Finalmente, intentemos ver si podemos visualizar los clusters usando la función *fviz_cluster*
```{r}
fviz_cluster(list(data = psicograficos, cluster = sub_grp))
```
```{r
```
# Ordenar un data frame
También podemos ordenar por los valores numéricos o alfabéticos de cada columna.
La función order() la posición del caso en función de la variable.
Por ejemplo
```{r}
orden_partidos <-order(goleadores_df$partidos, decreasing = TRUE)
orden_partidos
```
Ahí se puede ver como el jugador en la segunda fila (Angel Labruna) es el que más partido tiene, por ese el número de su fila aparece de primero en el vector. El segundo jugador con más goles es Miguel Brindisi, por lo que su fila (8) está en la segunda posición.
knitr::opts_chunk$set(echo = TRUE)
# Imprimir el DF mtcars
mtcars
# Usa head() en mtcars
head(mtcars)
# Usa tail() en mtcars
tail(mtcars)
# Revisemos la estructura de mtcars con str()
str(mtcars)
# Definición de los vectores
nombre <- c("Arseio Erico", "Angel Labruna", "Herminio Masantonio", "Manuel Pelegrina", "Martín Palermo", "José Sanfilippo", "Carlos Bianchi", "Miguel Brindisi")
goles <- c(295,293,256,229,227,226,206,194)
partidos <- c(332,515,358,229,410,330,324,441)
argentino_si <- c(FALSE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE)
equipo <- c("Independiente","River","Huracán","Estudiantes","Boca Juniors","San Lorenzo","Velez Sarfield","Huracán")
# Una vez creados los vectores, hacemos el data frame y lo llamamos goleadores_df
goleadores_df <-data.frame(nombre,goles,partidos,argentino_si,equipo)
# Aprovechemos y apliquemos lo aprendido viendo la estructura del nuevo DF
str(goleadores_df)
# veamos cuántos partidos jugó Martín Palermo en su carrera (fila 5, columna 2)
goleadores_df[5,2]
# ahora veamos todos los valores para Carlos Bianchi (la fila 7 completa)
goleadores_df[7,]
goleadores_df[,4]
goleadores_df[,"argentino_si"]
argentino_vector <- goleadores_df$argentino_si # Noten que este código crea un vector aparte, llamado argentino_vector
argentino_vector
goleadores_df[argentino_vector,]
goleadores_df[goles > 250,]
orden_partidos <-order(goleadores_df$partidos, decreasing = TRUE)
orden_partidos
yolo=TRUE
knitr::opts_chunk$set(echo = TRUE)
x <- 5
x > 3 & x < 10
